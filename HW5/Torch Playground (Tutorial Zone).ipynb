{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8be7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ECGR 5105 - Intro to Machine Learning\n",
    "Torch Learning Grounds. Not a homework Submission File\n",
    "Phillip Harmon\n",
    "\"\"\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be98affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362665bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model\n",
    "def model(x, w):\n",
    "    return w[2] * x * x + w[1] * x + w[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "783240b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the loss function\n",
    "def cost(y_p, y):\n",
    "    square_error = (y_p - y)**2\n",
    "    return square_error.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e60c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Forward Pass Function\n",
    "def forward_pass(x, y, params, enable_grad):\n",
    "    with torch.set_grad_enabled(enable_grad):\n",
    "        loss = cost( model(x, params) , y)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c051d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 0.00670528132468462\n",
      "Epoch 1000, Loss 0.0028758146800100803\n",
      "Epoch 1500, Loss 0.0023862847592681646\n",
      "Epoch 2000, Loss 0.0023079682141542435\n",
      "Epoch 2500, Loss 0.0022814751137048006\n",
      "Epoch 3000, Loss 0.002262611174955964\n",
      "Epoch 3500, Loss 0.002245859242975712\n",
      "Epoch 4000, Loss 0.0022304588928818703\n",
      "Epoch 4500, Loss 0.0022162289824336767\n",
      "Epoch 5000, Loss 0.002203074051067233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0247,  0.8415,  0.1799], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Custom Gradient Descent\n",
    "No Scaling or Validation\n",
    "\"\"\"\n",
    "\n",
    "#Define the Training Loop\n",
    "def train_loop(epochs, learn_rate, params, x, y):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        \n",
    "        y_p = model(x, params)\n",
    "        loss = cost(y_p, y)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            params -= learn_rate * params.grad\n",
    "            \n",
    "        if epoch% 500 == 0:\n",
    "            print('Epoch {}, Loss {}'.format(epoch, loss))\n",
    "\n",
    "    return params\n",
    "\n",
    "#Input Dataset Definition\n",
    "\n",
    "#measurement\n",
    "x = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4])\n",
    "#celcius\n",
    "y = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0])\n",
    "#Cleaning the inputs\n",
    "x = (x - x.min()) / (x.max() - x.min())\n",
    "y = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "#Define Constructs\n",
    "epochs = 5000\n",
    "learn_rate = 1e-2\n",
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = torch.optim.SGD([params], lr=learn_rate)\n",
    "\n",
    "#Perform the training\n",
    "\n",
    "train_loop(\n",
    "    epochs = epochs,\n",
    "    learn_rate = learn_rate,\n",
    "    params = params,\n",
    "    x = x,\n",
    "    y = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20c36ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 0.00670528132468462\n",
      "Epoch 1000, Loss 0.0028758146800100803\n",
      "Epoch 1500, Loss 0.0023862847592681646\n",
      "Epoch 2000, Loss 0.0023079682141542435\n",
      "Epoch 2500, Loss 0.0022814751137048006\n",
      "Epoch 3000, Loss 0.002262611174955964\n",
      "Epoch 3500, Loss 0.002245859242975712\n",
      "Epoch 4000, Loss 0.0022304588928818703\n",
      "Epoch 4500, Loss 0.0022162289824336767\n",
      "Epoch 5000, Loss 0.002203074051067233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0247,  0.8415,  0.1799], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "SGD Optimizer\n",
    "No Scaling or Validation\n",
    "\"\"\"\n",
    "\n",
    "#Define the Training Loop\n",
    "def train_loop(epochs, optimizer, params, x, y):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        y_p = model(x, params)\n",
    "        loss = cost(y_p, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        if epoch% 500 == 0:\n",
    "            print('Epoch {}, Loss {}'.format(epoch, loss))\n",
    "\n",
    "    return params\n",
    "\n",
    "#Input Dataset Definition\n",
    "\n",
    "#measurement\n",
    "x = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4])\n",
    "#celcius\n",
    "y = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0])\n",
    "#Cleaning the inputs\n",
    "x = (x - x.min()) / (x.max() - x.min())\n",
    "y = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "#Define Constructs\n",
    "epochs = 5000\n",
    "learn_rate = 1e-2\n",
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = torch.optim.SGD([params], lr=learn_rate)\n",
    "\n",
    "#Perform the training\n",
    "\n",
    "train_loop(\n",
    "    epochs = epochs,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    x = x,\n",
    "    y = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4304b0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 0.002141732955351472\n",
      "Epoch 1000, Loss 0.0020466074347496033\n",
      "Epoch 1500, Loss 0.0020434700418263674\n",
      "Epoch 2000, Loss 0.0020421408116817474\n",
      "Epoch 2500, Loss 0.0020417815539985895\n",
      "Epoch 3000, Loss 0.0020417245104908943\n",
      "Epoch 3500, Loss 0.0020417196210473776\n",
      "Epoch 4000, Loss 0.0020417184568941593\n",
      "Epoch 4500, Loss 0.0020417189225554466\n",
      "Epoch 5000, Loss 0.0020417189225554466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0029, 0.6968, 0.3195], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Adam Optimizer\n",
    "No Scaling or Validation\n",
    "\"\"\"\n",
    "\n",
    "#Define the Training Loop\n",
    "def train_loop(epochs, optimizer, params, x, y):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        y_p = model(x, params)\n",
    "        loss = cost(y_p, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "            \n",
    "        if epoch% 500 == 0:\n",
    "            print('Epoch {}, Loss {}'.format(epoch, loss))\n",
    "\n",
    "    return params\n",
    "\n",
    "#Input Dataset Definition\n",
    "\n",
    "#measurement\n",
    "x = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4])\n",
    "#celcius\n",
    "y = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0])\n",
    "#Cleaning the inputs\n",
    "x = (x - x.min()) / (x.max() - x.min())\n",
    "y = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "#Define Constructs\n",
    "epochs = 5000\n",
    "learn_rate = 1e-2\n",
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = torch.optim.Adam([params], lr=learn_rate)\n",
    "\n",
    "#Perform the training\n",
    "\n",
    "train_loop(\n",
    "    epochs = epochs,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    x = x,\n",
    "    y = y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8635b95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Training Loss = 1.0765001773834229 | Validation Loss = 1.1896332502365112\n",
      "Epoch 2 | Training Loss = 1.0390621423721313 | Validation Loss = 1.1511130332946777\n",
      "Epoch 3 | Training Loss = 1.002382755279541 | Validation Loss = 1.1132497787475586\n",
      "Epoch 500 | Training Loss = 0.002299879677593708 | Validation Loss = 0.0015392601490020752\n",
      "Epoch 1000 | Training Loss = 0.0022700007539242506 | Validation Loss = 0.0013620927929878235\n",
      "Epoch 1500 | Training Loss = 0.0022695520892739296 | Validation Loss = 0.0013421372277662158\n",
      "Epoch 2000 | Training Loss = 0.002269384451210499 | Validation Loss = 0.0013280060375109315\n",
      "Epoch 2500 | Training Loss = 0.002269347198307514 | Validation Loss = 0.0013203400885686278\n",
      "Epoch 3000 | Training Loss = 0.0022693423088639975 | Validation Loss = 0.0013172781327739358\n",
      "Epoch 3500 | Training Loss = 0.0022693416103720665 | Validation Loss = 0.001316437846980989\n",
      "Epoch 4000 | Training Loss = 0.002269341377541423 | Validation Loss = 0.0013162958202883601\n",
      "Epoch 4500 | Training Loss = 0.0022693409118801355 | Validation Loss = 0.0013162924442440271\n",
      "Epoch 5000 | Training Loss = 0.0022693402133882046 | Validation Loss = 0.0013162875548005104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0010,  0.7474,  0.2713], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Adam Optimizer\n",
    "T/V Split\n",
    "No Scaling\n",
    "\"\"\"\n",
    "\n",
    "#Define the Training Loop\n",
    "def train_loop(epochs, optimizer, params, x_t, y_t, x_v, y_v):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        loss_t = forward_pass(\n",
    "            x = x_t,\n",
    "            y = y_t,\n",
    "            params = params,\n",
    "            enable_grad = True)\n",
    "        \n",
    "        loss_v = forward_pass(\n",
    "            x = x_v,\n",
    "            y = y_v,\n",
    "            params = params,\n",
    "            enable_grad = False)\n",
    "        \n",
    "        if epoch <= 3 or epoch % 500 == 0:\n",
    "            print('Epoch {} | Training Loss = {} | Validation Loss = {}'.format(epoch, loss_t, loss_v))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_t.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return params\n",
    "\n",
    "#Input Dataset Definition\n",
    "\n",
    "#measurement\n",
    "x = torch.tensor([35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4])\n",
    "#celcius\n",
    "y = torch.tensor([0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0])\n",
    "#Cleaning the inputs\n",
    "x = (x - x.min()) / (x.max() - x.min())\n",
    "y = (y - y.min()) / (y.max() - y.min())\n",
    "\n",
    "#Train/Test Split\n",
    "split = int(0.2 * x.shape[0])\n",
    "shuffle_index = torch.randperm(x.shape[0])\n",
    "index_t = shuffle_index[:-split]\n",
    "index_v = shuffle_index[-split:]\n",
    "x_t = x[index_t]\n",
    "y_t = y[index_t]\n",
    "x_v = x[index_v]\n",
    "y_v = y[index_v]\n",
    "\n",
    "#Define Constructs\n",
    "epochs = 5000\n",
    "learn_rate = 1e-2\n",
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "optimizer = torch.optim.Adam([params], lr=learn_rate)\n",
    "\n",
    "#Perform the training\n",
    "\n",
    "train_loop(\n",
    "    epochs = epochs,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    x_t = x_t,\n",
    "    y_t = y_t,\n",
    "    x_v = x_v,\n",
    "    y_v = y_v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ccdcaf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5608039798394725"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.02620089240372181 - 0.011507327668368816) / 0.02620089240372181"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b99fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
